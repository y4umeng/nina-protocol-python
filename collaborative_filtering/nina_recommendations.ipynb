{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "NtLZjbGGnJyL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy import sparse\n",
        "from api import get_all_accounts, get_collected_by_public_key, get_release_by_public_key"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------\n",
        "#  CREATE DATASET\n",
        "#  https://stackoverflow.com/questions/59245143/how-to-turn-a-column-of-lists-in-pandas-to-a-sparse-dataframe-of-the-unique-valu\n",
        "#\n",
        "#  this cell takes 10 minutes to run. outputs nina_user_collections.csv which can be found in repo\n",
        "#  only run if current data is necessary\n",
        "#------------------\n",
        "\n",
        "accounts, _ = get_all_accounts(3000)\n",
        "df = {}\n",
        "print(len(accounts))\n",
        "count = 0\n",
        "for acc in accounts:\n",
        "  count += 1\n",
        "  if not count % 100: print(count)\n",
        "  try:\n",
        "    df[acc] = [[release.public_key for release in get_collected_by_public_key(acc)]]\n",
        "    if not len(df[acc][0]): del df[acc]\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "print(\"done w requests\")\n",
        "\n",
        "df = pd.DataFrame.from_dict(df,orient='index')\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "df = pd.DataFrame(mlb.fit_transform(df[0]),columns=mlb.classes_, index=df.index)\n",
        "\n",
        "df.to_csv('nina_user_collections.csv', index=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "bFZJSr4tDfHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------\n",
        "# LOAD THE DATASET\n",
        "#------------------\n",
        "\n",
        "data = pd.read_csv('nina_user_collections.csv', index_col=0)\n",
        "data_items = data.drop(data.columns[0],axis=1)\n"
      ],
      "metadata": {
        "id": "8GUipif9HdDT"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------\n",
        "# ITEM-ITEM CALCULATIONS\n",
        "#------------------------\n",
        "\n",
        "# As a first step we normalize the account vectors to unit vectors.\n",
        "\n",
        "# magnitude = sqrt(x2 + y2 + z2 + ...)\n",
        "magnitude = np.sqrt(np.square(data_items).sum(axis=1))\n",
        "\n",
        "# unitvector = (x / magnitude, y / magnitude, z / magnitude, ...)\n",
        "data_items = data_items.divide(magnitude, axis='index')\n",
        "\n",
        "def calculate_similarity(data_items):\n",
        "    \"\"\"Calculate the column-wise cosine similarity for a sparse\n",
        "    matrix. Return a new dataframe matrix with similarities.\n",
        "    \"\"\"\n",
        "    data_sparse = sparse.csr_matrix(data_items)\n",
        "    similarities = cosine_similarity(data_sparse.transpose())\n",
        "    sim = pd.DataFrame(data=similarities, index= data_items.columns, columns= data_items.columns)\n",
        "    return sim\n",
        "\n",
        "# Build the similarity matrix (this is item_matrix.csv in the repo)\n",
        "data_matrix = calculate_similarity(data_items)\n",
        "\n",
        "# Lets get the top 11 similar releases for https://ninaprotocol.com/9ybyxyNaKi9cm7jENmy26XBCazkEq3nu2KvQ2nTRumJS\n",
        "print(data_matrix.loc['9ybyxyNaKi9cm7jENmy26XBCazkEq3nu2KvQ2nTRumJS'].nlargest(11))"
      ],
      "metadata": {
        "id": "WlKtqzVI6Fue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00d63105-5077-440e-83c2-37b5937b9629"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2P6JUnmrPTVZSSeDvJCe3EFdnAV7PvAPNjT3wecWqtZs    1.0\n",
            "36dALkT9L88WR3PydN3QHBFpHzBgDt3qGfvaXnW9nSUp    1.0\n",
            "3TyXX1jeUCrfsyDy21kTMSoxfZC2mLVdYk5vkCJBZaBx    1.0\n",
            "3VDiNspnzWEQsUa1wRPSaBvMbtxHe5c8rVgv5dkzHqjU    1.0\n",
            "4RpgVX7U58pLZPEKJb95pCvxxJiL1bFGyGQNF8Hgqtrh    1.0\n",
            "5fSpw7aUcFLFSej75qnuZY8wwVy4sUmSExdWDxX3JVD2    1.0\n",
            "6ALby4N8adRqFWB9mZw3fgWj8z1uzrd1z8VTDXwDH11D    1.0\n",
            "6XERbjDd2myURWo21LYF74kXVLYqmUb8818Ptk5Z924o    1.0\n",
            "74iE8coUgAJRpAA5f43UDKUsWTxuHSDbHZbB9GQXAyuA    1.0\n",
            "7uoNjvp6cdSVQzE4ErGqCCUpWnx7J7pmFXHJEU4bzGzu    1.0\n",
            "94K4QzryBjXXcE1fyDiu2S1CeHMpwZd22ecVx8cfNNnX    1.0\n",
            "Name: 9ybyxyNaKi9cm7jENmy26XBCazkEq3nu2KvQ2nTRumJS, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------\n",
        "# USER-ITEM CALCULATIONS\n",
        "#------------------------\n",
        "\n",
        "# Construct a new dataframe with the 10 closest neighbours (most similar)\n",
        "# for each release.\n",
        "\n",
        "data_neighbours = pd.DataFrame(index=data_matrix.columns, columns=range(1,11))\n",
        "print(data_neighbours.shape)\n",
        "print(len(data_matrix.columns))\n",
        "for release in data_matrix.columns:\n",
        "  data_neighbours.loc[release] = data_matrix.loc[:, release].sort_values(ascending=False)[:10].index\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7QHM_3w7n0Q",
        "outputId": "942622d7-b411-400e-9cfc-af774273e0e7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1570, 10)\n",
            "1570\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommendations(user_key, num_recs):\n",
        "  # Get the releases the user has collected.\n",
        "  user_collection = [release.public_key for release in get_collected_by_public_key(user_key)]\n",
        "\n",
        "  # Construct the neighbourhood from the most similar releases to the\n",
        "  # ones our user has already collected.\n",
        "  most_similar_to_collection = data_neighbours.loc[user_collection]\n",
        "  similar_list = most_similar_to_collection.values.tolist()\n",
        "  similar_list = list(set([item for sublist in similar_list for item in sublist]))\n",
        "\n",
        "  neighbourhood = data_matrix[similar_list].loc[similar_list]\n",
        "\n",
        "  # A user vector containing only the neighbourhood releases and\n",
        "  # the known user owned releases.\n",
        "\n",
        "  user_vector = data.loc[user_key][similar_list]\n",
        "\n",
        "  # Calculate the score.\n",
        "  score = neighbourhood.dot(user_vector).div(neighbourhood.sum(axis=1))\n",
        "\n",
        "  # Drop the releases the user already owns.\n",
        "  score = score.drop(user_collection)\n",
        "\n",
        "  # print(user_collection)\n",
        "  return score.nlargest(num_recs)"
      ],
      "metadata": {
        "id": "sAXpLM_5dR_i"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------\n",
        "# EXAMPLE:\n",
        "#------------------------\n",
        "\n",
        "# Get top 5 recommendations for a user\n",
        "recs = get_recommendations('MW8D5zJcQ35orcYizKgGzx3tv8YM276ibznvesAvnas', 5)\n",
        "recs_info = [get_release_by_public_key(key) for key in recs.index.values]\n",
        "for release in recs_info:\n",
        "  print(f'{release.metadata.name}: {release.metadata.external_url}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwxPz7dqFe9a",
        "outputId": "616f94aa-7a31-45a7-baab-adaafcd1bc8a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teu - Um yes hello be well goodbye: https://ninaprotocol.com/ATvYwzdNMfSoaF59GXpF8S3Z2zUX3Eo6Aeg1pb6VXuL1\n",
            "Music For Graphic Designers - Italia: https://ninaprotocol.com/7MDavy863pJqvydrEBracZXSNnFtzXuzpaEspWGPoC5v\n",
            "Mifella - Milady You Are My Baby: https://ninaprotocol.com/6q4Xu44V79BmDAy6Cg3q1VQBTNGrZWAUvvEbNSfdXF1t\n",
            "The Transcendence Orchestra - Serviceable villain / An ancient city and several nuclear explosions: https://ninaprotocol.com/J1LkFQ76xe6u8ZB4i4dJNRPKvo9DdbYwVWmCuhAwEFSJ\n",
            "PANZERSCHOKOLADE - body speaking: https://ninaprotocol.com/EzF5ya9KjFWaShugKYiDm97a5nva2Np8gWwVK2iEN4Sw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------\n",
        "# REFERENCES:\n",
        "# https://medium.com/radon-dev/item-item-collaborative-filtering-with-binary-or-unary-data-e8f0b465b2c3\n",
        "# http://www.salemmarafi.com/code/collaborative-filtering-with-python/\n",
        "# https://realpython.com/build-recommendation-engine-collaborative-filtering/\n",
        "#------------------------"
      ],
      "metadata": {
        "id": "nRSAZU1Xg-Pf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}